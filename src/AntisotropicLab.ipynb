{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41182bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f47fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maria\\miniconda3\\envs\\lab4ComputerVision\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b77dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directorio de las imágenes de prueba\n",
    "IMAGE_DIR = \"BSDS500/BSDS500/data/images/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685373a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo del filtro anisotrópico\n",
    "def anisodiff(img, niter=1, kappa=50, gamma=0.1, step=(1.,1.), option=1, ploton=False):\n",
    "    \"\"\"\n",
    "    Anisotropic diffusion.\n",
    "    \"\"\"\n",
    "    if img.ndim == 3:\n",
    "        warnings.warn(\"Only grayscale images allowed, converting to 2D matrix\")\n",
    "        img = img.mean(2)\n",
    "    \n",
    "    img = img.astype('float32')\n",
    "    imgout = img.copy()\n",
    "    \n",
    "    deltaS = np.zeros_like(imgout)\n",
    "    deltaE = deltaS.copy()\n",
    "    NS = deltaS.copy()\n",
    "    EW = deltaS.copy()\n",
    "    gS = np.ones_like(imgout)\n",
    "    gE = gS.copy()\n",
    "    \n",
    "    for ii in range(niter):\n",
    "        deltaS[:-1,: ] = np.diff(imgout,axis=0)\n",
    "        deltaE[: ,:-1] = np.diff(imgout,axis=1)\n",
    "        \n",
    "        if option == 1:\n",
    "            gS = np.exp(-(deltaS/kappa)**2.)/step[0]\n",
    "            gE = np.exp(-(deltaE/kappa)**2.)/step[1]\n",
    "        elif option == 2:\n",
    "            gS = 1./(1.+(deltaS/kappa)**2.)/step[0]\n",
    "            gE = 1./(1.+(deltaE/kappa)**2.)/step[1]\n",
    "        \n",
    "        E = gE*deltaE\n",
    "        S = gS*deltaS\n",
    "        \n",
    "        NS[:] = S\n",
    "        EW[:] = E\n",
    "        NS[1:,:] -= S[:-1,:]\n",
    "        EW[:,1:] -= E[:,:-1]\n",
    "        \n",
    "        imgout += gamma*(NS+EW)\n",
    "    \n",
    "    return imgout\n",
    "\n",
    "class AnisotropicFilterDataset:\n",
    "    \"\"\"Clase para manejar el dataset y generar ventanas de entrenamiento\"\"\"\n",
    "    \n",
    "    def __init__(self, image_dir, window_size=32, num_samples=50000):\n",
    "        self.image_dir = image_dir\n",
    "        self.window_size = window_size\n",
    "        self.num_samples = num_samples\n",
    "        self.images = []\n",
    "        self.filtered_images = []\n",
    "        \n",
    "    def load_and_process_images(self):\n",
    "        \"\"\"Cargar imágenes, convertir a escala de grises y aplicar filtro anisotrópico\"\"\"\n",
    "        print(\"Cargando y procesando imágenes...\")\n",
    "        \n",
    "        image_files = [f for f in os.listdir(self.image_dir) if f.endswith(('.jpg', '.png', '.bmp'))]\n",
    "        \n",
    "        for filename in tqdm(image_files, desc=\"Procesando imágenes\"):\n",
    "            # Cargar imagen\n",
    "            img_path = os.path.join(self.image_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                # Convertir a escala de grises\n",
    "                if len(img.shape) == 3:\n",
    "                    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                else:\n",
    "                    gray_img = img\n",
    "                \n",
    "                # Normalizar a [0, 1]\n",
    "                gray_img = gray_img.astype(np.float32) / 255.0\n",
    "                \n",
    "                # Aplicar filtro anisotrópico\n",
    "                filtered_img = anisodiff(gray_img, \n",
    "                                       niter=50, \n",
    "                                       kappa=20, \n",
    "                                       gamma=0.2, \n",
    "                                       step=(1.,1.), \n",
    "                                       option=1, \n",
    "                                       ploton=False)\n",
    "                \n",
    "                self.images.append(gray_img)\n",
    "                self.filtered_images.append(filtered_img)\n",
    "        \n",
    "        print(f\"Procesadas {len(self.images)} imágenes\")\n",
    "    \n",
    "    def generate_windows(self):\n",
    "        \"\"\"Generar ventanas aleatorias de las imágenes para entrenamiento\"\"\"\n",
    "        print(f\"Generando {self.num_samples} ventanas de {self.window_size}x{self.window_size}...\")\n",
    "        \n",
    "        X_windows = []\n",
    "        y_windows = []\n",
    "        \n",
    "        for _ in tqdm(range(self.num_samples), desc=\"Generando ventanas\"):\n",
    "            # Seleccionar imagen aleatoria\n",
    "            img_idx = random.randint(0, len(self.images) - 1)\n",
    "            original_img = self.images[img_idx]\n",
    "            filtered_img = self.filtered_images[img_idx]\n",
    "            \n",
    "            # Obtener dimensiones\n",
    "            h, w = original_img.shape\n",
    "            \n",
    "            # Verificar que la imagen sea lo suficientemente grande\n",
    "            if h >= self.window_size and w >= self.window_size:\n",
    "                # Seleccionar posición aleatoria\n",
    "                y_start = random.randint(0, h - self.window_size)\n",
    "                x_start = random.randint(0, w - self.window_size)\n",
    "                \n",
    "                # Extraer ventanas\n",
    "                x_window = original_img[y_start:y_start+self.window_size, \n",
    "                                      x_start:x_start+self.window_size]\n",
    "                y_window = filtered_img[y_start:y_start+self.window_size, \n",
    "                                      x_start:x_start+self.window_size]\n",
    "                \n",
    "                X_windows.append(x_window)\n",
    "                y_windows.append(y_window)\n",
    "        \n",
    "        # Convertir a arrays numpy y añadir dimensión de canal\n",
    "        X_windows = np.array(X_windows)[..., np.newaxis]\n",
    "        y_windows = np.array(y_windows)[..., np.newaxis]\n",
    "        \n",
    "        print(f\"Generadas {len(X_windows)} ventanas\")\n",
    "        return X_windows, y_windows\n",
    "    \n",
    "    def split_data(self, X, y, test_size=0.2, val_size=0.1):\n",
    "        \"\"\"Dividir datos en entrenamiento, validación y prueba\"\"\"\n",
    "        # Dividir en entrenamiento + validación y prueba\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Dividir temp en entrenamiento y validación\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp, test_size=val_size/(1-test_size), random_state=42\n",
    "        )\n",
    "        \n",
    "        print(f\"Datos divididos:\")\n",
    "        print(f\"  Entrenamiento: {len(X_train)} muestras\")\n",
    "        print(f\"  Validación: {len(X_val)} muestras\")\n",
    "        print(f\"  Prueba: {len(X_test)} muestras\")\n",
    "        \n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def create_unet_model(input_size=(32, 32, 1), depth=4):\n",
    "    \"\"\"Crear modelo U-Net\"\"\"\n",
    "    inputs = keras.Input(shape=input_size)\n",
    "    \n",
    "    # Encoder (contracción)\n",
    "    skips = []\n",
    "    x = inputs\n",
    "    \n",
    "    filters = 64\n",
    "    for i in range(depth):\n",
    "        # Convoluciones\n",
    "        x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
    "        \n",
    "        # Guardar para skip connection\n",
    "        if i < depth - 1:  # No guardar la última capa\n",
    "            skips.append(x)\n",
    "            x = layers.MaxPooling2D(2)(x)\n",
    "            filters *= 2\n",
    "    \n",
    "    # Decoder (expansión)\n",
    "    for i in range(depth - 1):\n",
    "        filters //= 2\n",
    "        \n",
    "        # Upsampling\n",
    "        x = layers.Conv2DTranspose(filters, 2, strides=2, padding='same')(x)\n",
    "        \n",
    "        # Skip connection\n",
    "        skip = skips.pop()\n",
    "        x = layers.Concatenate()([x, skip])\n",
    "        \n",
    "        # Convoluciones\n",
    "        x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
    "        x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
    "    \n",
    "    # Capa de salida\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name='U-Net')\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):\n",
    "    \"\"\"Entrenar el modelo U-Net\"\"\"\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    ]\n",
    "    \n",
    "    # Entrenar\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def sliding_window_inference(model, image, window_size=32, stride=16):\n",
    "    \"\"\"Realizar inferencia usando ventanas deslizantes\"\"\"\n",
    "    h, w = image.shape\n",
    "    \n",
    "    # Crear imagen de salida y matriz de conteo para promedio\n",
    "    output_image = np.zeros_like(image)\n",
    "    count_matrix = np.zeros_like(image)\n",
    "    \n",
    "    # Calcular número de ventanas\n",
    "    num_windows_h = (h - window_size) // stride + 1\n",
    "    num_windows_w = (w - window_size) // stride + 1\n",
    "    \n",
    "    # Preparar batch de ventanas\n",
    "    windows = []\n",
    "    positions = []\n",
    "    \n",
    "    for i in range(0, h - window_size + 1, stride):\n",
    "        for j in range(0, w - window_size + 1, stride):\n",
    "            window = image[i:i+window_size, j:j+window_size]\n",
    "            windows.append(window)\n",
    "            positions.append((i, j))\n",
    "    \n",
    "    # Convertir a tensor\n",
    "    windows = np.array(windows)[..., np.newaxis]\n",
    "    \n",
    "    # Realizar predicción\n",
    "    predictions = model.predict(windows, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Reconstruir imagen\n",
    "    for k, (i, j) in enumerate(positions):\n",
    "        pred_window = predictions[k, :, :, 0]\n",
    "        output_image[i:i+window_size, j:j+window_size] += pred_window\n",
    "        count_matrix[i:i+window_size, j:j+window_size] += 1\n",
    "    \n",
    "    # Promedio donde hay solapamiento\n",
    "    output_image = np.divide(output_image, count_matrix, \n",
    "                           out=np.zeros_like(output_image), \n",
    "                           where=count_matrix!=0)\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "def evaluate_model(model, test_image_path, window_size=32):\n",
    "    \"\"\"Evaluar modelo con una imagen de prueba\"\"\"\n",
    "    # Cargar imagen de prueba\n",
    "    test_img = cv2.imread(test_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    test_img = test_img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Aplicar filtro anisotrópico real\n",
    "    ground_truth = anisodiff(test_img, niter=50, kappa=20, gamma=0.2, \n",
    "                           step=(1.,1.), option=1, ploton=False)\n",
    "    \n",
    "    # Realizar inferencia con U-Net\n",
    "    predicted = sliding_window_inference(model, test_img, window_size)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    mse = np.mean((ground_truth - predicted) ** 2)\n",
    "    psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "    \n",
    "    # Visualizar resultados\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(test_img, cmap='gray')\n",
    "    plt.title('Imagen Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(ground_truth, cmap='gray')\n",
    "    plt.title('Filtro Anisotrópico Real')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(predicted, cmap='gray')\n",
    "    plt.title(f'U-Net Predicción\\nPSNR: {psnr:.2f} dB')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return mse, psnr\n",
    "\n",
    "# Función principal para ejecutar el pipeline completo\n",
    "def main():\n",
    "    \"\"\"Pipeline principal del laboratorio\"\"\"\n",
    "    \n",
    "    # Configuración\n",
    "    IMAGE_DIR = \"BSDS500/BSDS500/data/images/test/\"\n",
    "    WINDOW_SIZE = 32\n",
    "    NUM_SAMPLES = 100000\n",
    "    \n",
    "    print(\"=== Laboratorio U-Net para Filtros Anisotrópicos ===\\n\")\n",
    "    \n",
    "    # 1. Crear dataset y procesar imágenes\n",
    "    print(\"Paso 1: Procesando imágenes...\")\n",
    "    dataset = AnisotropicFilterDataset(IMAGE_DIR, WINDOW_SIZE, NUM_SAMPLES)\n",
    "    dataset.load_and_process_images()\n",
    "    \n",
    "    # 2. Generar ventanas\n",
    "    print(\"\\nPaso 2: Generando ventanas de entrenamiento...\")\n",
    "    X, y = dataset.generate_windows()\n",
    "    \n",
    "    # 3. Dividir datos\n",
    "    print(\"\\nPaso 3: Dividiendo datos...\")\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = dataset.split_data(X, y)\n",
    "    \n",
    "    # 4. Crear y entrenar modelo\n",
    "    print(\"\\nPaso 4: Creando modelo U-Net...\")\n",
    "    model = create_unet_model(input_size=(WINDOW_SIZE, WINDOW_SIZE, 1))\n",
    "    model.summary()\n",
    "    \n",
    "    print(\"\\nPaso 5: Entrenando modelo...\")\n",
    "    history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # 5. Evaluar modelo\n",
    "    print(\"\\nPaso 6: Evaluando modelo...\")\n",
    "    \n",
    "    # Evaluar en conjunto de prueba\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Pérdida en conjunto de prueba: {test_loss}\")\n",
    "    \n",
    "    # Guardar modelo\n",
    "    model.save('unet_anisotropic_filter.h5')\n",
    "    print(\"Modelo guardado como 'unet_anisotropic_filter.h5'\")\n",
    "    \n",
    "    print(\"\\n=== Laboratorio completado ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_with_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
