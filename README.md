# ğŸ§  Laboratorio #4 â€“ U-Net + Filtro AnisotrÃ³pico de Perona-Malik  
### VisiÃ³n por Computadora  
**Universidad del Valle de Guatemala**  
ğŸ“… 31 de mayo 2025  

---

## ğŸ‘¥ Integrantes

- MarÃ­a Marta RamÃ­rez Gil â€“ 21342  
- Gustavo AndrÃ©s GonzÃ¡lez Pineda â€“ 21438  
- JosÃ© Pablo Orellana Orellana â€“ 21970  
- Diego Alberto Leiva â€“ 21752  

---

## ğŸ§© DescripciÃ³n del Proyecto

Este laboratorio implementa una red neuronal tipo **U-Net** combinada con el **filtro anisotrÃ³pico de Perona-Malik**, aplicada a imÃ¡genes en escala de grises. El objetivo es filtrar ruido preservando bordes importantes, utilizando la base de datos **BSDS500**.

Se incluye preprocesamiento, entrenamiento del modelo y evaluaciÃ³n visual.  

---

## ğŸ§  Filtro AnisotrÃ³pico de Perona-Malik

El filtro de Perona-Malik es una tÃ©cnica de **difusiÃ³n adaptativa** que suaviza regiones homogÃ©neas en una imagen mientras **preserva bordes definidos**. A diferencia de filtros como el Gaussian Blur, no difumina bordes sino que los respeta gracias a su formulaciÃ³n no lineal.

### Beneficios
- PreservaciÃ³n de bordes
- ReducciÃ³n eficiente de ruido
- Ideal para imÃ¡genes mÃ©dicas, satelitales y visualizaciÃ³n cientÃ­fica

### Referencias clave
- Perona, P., & Malik, J. (1990). _Scale-space and edge detection using anisotropic diffusion_. [IEEE](https://scispace.com/papers/scale-space-and-edge-detection-using-anisotropic-diffusion-2my7clurjr)  
- Guidotti, P. (2025). _Anisotropic Diffusions of Image Processing From Perona-Malik_. [PDF](https://www.math.uci.edu/~gpatrick/source/papers/G131.pdf)  
- BSDS500 Dataset â€“ [GitHub](https://github.com/BIDS/BSDS500)  
- Kaggle Notebooks â€“ [Kaggle](https://www.kaggle.com/code/kmader/anisotropic-diffusion-example)

---

## âš™ï¸ Requerimientos

Incluidos en el archivo `requirements.txt`:

- numpy  
- tensorflow  
- opencv-python  
- matplotlib  
- scikit-learn  
- tqdm  

**Se recomienda fuertemente usar una GPU** para acelerar el entrenamiento.  

---

## ğŸš€ Instrucciones de uso

### 1. Crear un ambiente de conda
```bash
conda create -n lab4_unet python=3.10
conda activate lab4_unet
```

### 2. Instalar los requerimientos
```bash
pip install -r requirements.txt
```

### 3. Clonar el repositorio
```bash
git clone <url-del-repo>
cd lab4_unet
```

### 4. Ejecutar el cÃ³digo principal
```bash
python main.py
```

---

## ğŸ§ª Resultados Esperados

- VisualizaciÃ³n de mÃ¡scaras predichas vs ground truth  
- ComparaciÃ³n de imÃ¡genes antes y despuÃ©s del filtrado  
- GrÃ¡ficas de desempeÃ±o del modelo  

---

## ğŸ“Œ Notas Finales

- Proyecto 100% reproducible  
- CÃ³digo limpio y modular  
- Compatible con Google Colab

# ğŸ› ï¸ Recomendaciones para Mejorar la Calidad de ImÃ¡genes Filtradas

Durante las pruebas del modelo **U-Net** entrenado con ventanas deslizantes, se observaron salidas pixeladas o con artefactos tipo mosaico. A continuaciÃ³n se listan recomendaciones clave para mejorar la calidad del resultado final:

## âœ… Recomendaciones

| Paso | RecomendaciÃ³n |
|------|---------------|
| âœ… 1 | **Aumentar el tamaÃ±o de ventana (`window_size`)**: Se sugiere usar `64` o `128` para que el modelo capture estructuras mÃ¡s amplias. |
| âœ… 2 | **Reducir el `stride` en la inferencia**: Usar `stride=8` o `4` suaviza la reconstrucciÃ³n al solapar mÃ¡s las ventanas. |
| âœ… 3 | **Ampliar la capacidad del modelo U-Net**: Agregar mÃ¡s filtros por capa (por ejemplo: `64 â†’ 128 â†’ 256 â†’ 512`) mejora la capacidad de aprendizaje. |
| âœ… 4 | **Revisar la activaciÃ³n de salida**: Sustituir `sigmoid` por `linear` o `tanh` y normalizar las imÃ¡genes en `[0, 1]` o `[-1, 1]` segÃºn corresponda. |
| âœ… 5 | **Utilizar funciones de pÃ©rdida perceptuales**: Probar `SSIM`, `MAE` o una pÃ©rdida mixta como: |

```python
def mixed_loss(y_true, y_pred):
    return 0.8 * tf.reduce_mean(tf.square(y_true - y_pred)) + \
           0.2 * tf.image.ssim(y_true, y_pred, max_val=1.0)
```
| âœ… 6 | **Reducir el nivel de suavizado del filtro anisotrÃ³pico**: Usar valores mÃ¡s suaves como `niter=20`, `gamma=0.1` evita que se pierdan detalles esenciales en las imÃ¡genes objetivo. |